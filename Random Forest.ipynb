{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "085fc872",
   "metadata": {},
   "source": [
    "Talk about random forest and how it works. Write specific context about its use cases here with this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df55815c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import LeaveOneOut, cross_val_score, StratifiedKFold, train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "df = pd.read_csv('data\\heart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "871536cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for model comparison\n",
    "\n",
    "def collect_metrics(y_true, y_pred, method_name):\n",
    "    return {\n",
    "        'method': method_name,\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred),\n",
    "        'recall': recall_score(y_true, y_pred),\n",
    "        'f1_score': f1_score(y_true, y_pred)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0999b6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "\n",
    "# Seperate into target and predictors\n",
    "X = df.drop('HeartDisease', axis=1)\n",
    "y = df['HeartDisease']\n",
    "\n",
    "# Identify column types\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Preprocessing and model pipeline\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
    "    ('num', 'passthrough', numeric_cols)\n",
    "])\n",
    "clf = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=49))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff03bc37",
   "metadata": {},
   "source": [
    "Write about model hyperparameters, why they are important and how grid search can be used to optimize model fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "943daa20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3136 candidates, totalling 15680 fits\n",
      "Best Parameters: {'classifier__max_depth': 5, 'classifier__max_features': 'sqrt', 'classifier__min_samples_leaf': 9, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 25}\n",
      "Best F1 Score: 0.8637436921919784\n"
     ]
    }
   ],
   "source": [
    "# Perform grid search for optimal hyperparameters and update classifier pipeline\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': list(range(25, 200, 25)),\n",
    "    'classifier__max_depth': [None] + list(range(5, 20, 5)),\n",
    "    'classifier__min_samples_split': list(range(2, 10)),\n",
    "    'classifier__min_samples_leaf': list(range(1, 15, 2)),\n",
    "    'classifier__max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Create GridSearchCV using Stratified K-Fold for classification\n",
    "grid_search = GridSearchCV(\n",
    "    clf,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,  # Use all processor cores to speed up grid search\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit the grid search\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Print the results\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best F1 Score:\", grid_search.best_score_)\n",
    "\n",
    "# Update parameters for subsequent model evaluation\n",
    "best_clf = grid_search.best_estimator_\n",
    "clf = best_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214383c9",
   "metadata": {},
   "source": [
    "Talk about cross validation methods and standard test train split and why we use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "900ee48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit random forest model using optimized hyperparameters and test/train split\n",
    "\n",
    "metrics_list = []\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=49)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "metrics_list.append(collect_metrics(y_test, y_pred, method_name='Train/Test Split'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83b22f1",
   "metadata": {},
   "source": [
    "Talk about k fold cross validation, why we use it and why we settled on 10 folds here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bb01f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=49)\n",
    "y_true_kf = []\n",
    "y_pred_kf = []\n",
    "\n",
    "for train_idx, test_idx in kfold.split(X, y):\n",
    "    clf.fit(X.iloc[train_idx], y.iloc[train_idx])\n",
    "    pred = clf.predict(X.iloc[test_idx])\n",
    "    y_true_kf.extend(y.iloc[test_idx])\n",
    "    y_pred_kf.extend(pred)\n",
    "\n",
    "metrics_list.append(collect_metrics(y_true_kf, y_pred_kf, method_name='Stratified K-Fold'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbee88d",
   "metadata": {},
   "source": [
    "Talk about leave one out cross validation and make sure to highlight computational inefficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "caa7eadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave-One-Out Cross-Validation\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "y_true_loo = []\n",
    "y_pred_loo = []\n",
    "\n",
    "for train_idx, test_idx in loo.split(X):\n",
    "    clf.fit(X.iloc[train_idx], y.iloc[train_idx])\n",
    "    pred = clf.predict(X.iloc[test_idx])\n",
    "    y_true_loo.append(y.iloc[test_idx].values[0])\n",
    "    y_pred_loo.append(pred[0])\n",
    "\n",
    "metrics_list.append(collect_metrics(y_true_loo, y_pred_loo, method_name='LOOCV'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe5c0d4",
   "metadata": {},
   "source": [
    "In the final latex document we will need to make sure we use this data to compare model fits using various methods. Also talk about these metrics and why they matter, plus why we didn't use something else such as AUC-ROC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1105ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              method  accuracy  precision    recall  f1_score\n",
      "0   Train/Test Split  0.875000   0.883495  0.892157  0.887805\n",
      "1              LOOCV  0.866013   0.857143  0.909449  0.882521\n",
      "2  Stratified K-Fold  0.867102   0.860075  0.907480  0.883142\n"
     ]
    }
   ],
   "source": [
    "# Compare results of model fitting\n",
    "\n",
    "results_df = pd.DataFrame(metrics_list)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe95b86",
   "metadata": {},
   "source": [
    "Summary, even though tghere is essentially no performance difference between cross validation types here we should use k-fold CV as the preffered method as it is expected to perform better than a standard test-train split on larger and more complex datasets and LOOCV is far too computationally expensive to scale well to other data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211403a3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
